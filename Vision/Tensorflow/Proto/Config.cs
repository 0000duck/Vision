// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: config.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Vision.Tensorflow.Proto {

  /// <summary>Holder for reflection information generated from config.proto</summary>
  public static partial class ConfigReflection {

    #region Descriptor
    /// <summary>File descriptor for config.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static ConfigReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Cgxjb25maWcucHJvdG8SCnRlbnNvcmZsb3caEGNvc3RfZ3JhcGgucHJvdG8a",
            "C2dyYXBoLnByb3RvGhBzdGVwX3N0YXRzLnByb3RvGgtkZWJ1Zy5wcm90bxoN",
            "Y2x1c3Rlci5wcm90bxoVcmV3cml0ZXJfY29uZmlnLnByb3RvIs0DCgpHUFVP",
            "cHRpb25zEicKH3Blcl9wcm9jZXNzX2dwdV9tZW1vcnlfZnJhY3Rpb24YASAB",
            "KAESFgoOYWxsb2NhdG9yX3R5cGUYAiABKAkSHwoXZGVmZXJyZWRfZGVsZXRp",
            "b25fYnl0ZXMYAyABKAMSFAoMYWxsb3dfZ3Jvd3RoGAQgASgIEhsKE3Zpc2li",
            "bGVfZGV2aWNlX2xpc3QYBSABKAkSIgoacG9sbGluZ19hY3RpdmVfZGVsYXlf",
            "dXNlY3MYBiABKAUSJAoccG9sbGluZ19pbmFjdGl2ZV9kZWxheV9tc2VjcxgH",
            "IAEoBRIcChRmb3JjZV9ncHVfY29tcGF0aWJsZRgIIAEoCBI5CgxleHBlcmlt",
            "ZW50YWwYCSABKAsyIy50ZW5zb3JmbG93LkdQVU9wdGlvbnMuRXhwZXJpbWVu",
            "dGFsGoYBCgxFeHBlcmltZW50YWwSSwoPdmlydHVhbF9kZXZpY2VzGAEgAygL",
            "MjIudGVuc29yZmxvdy5HUFVPcHRpb25zLkV4cGVyaW1lbnRhbC5WaXJ0dWFs",
            "RGV2aWNlcxopCg5WaXJ0dWFsRGV2aWNlcxIXCg9tZW1vcnlfbGltaXRfbWIY",
            "ASADKAIihQMKEE9wdGltaXplck9wdGlvbnMSKwojZG9fY29tbW9uX3N1YmV4",
            "cHJlc3Npb25fZWxpbWluYXRpb24YASABKAgSGwoTZG9fY29uc3RhbnRfZm9s",
            "ZGluZxgCIAEoCBIkChxtYXhfZm9sZGVkX2NvbnN0YW50X2luX2J5dGVzGAYg",
            "ASgDEhwKFGRvX2Z1bmN0aW9uX2lubGluaW5nGAQgASgIEjUKCW9wdF9sZXZl",
            "bBgDIAEoDjIiLnRlbnNvcmZsb3cuT3B0aW1pemVyT3B0aW9ucy5MZXZlbBJF",
            "ChBnbG9iYWxfaml0X2xldmVsGAUgASgOMisudGVuc29yZmxvdy5PcHRpbWl6",
            "ZXJPcHRpb25zLkdsb2JhbEppdExldmVsIiAKBUxldmVsEgYKAkwxEAASDwoC",
            "TDAQ////////////ASJDCg5HbG9iYWxKaXRMZXZlbBILCgdERUZBVUxUEAAS",
            "EAoDT0ZGEP///////////wESCAoET05fMRABEggKBE9OXzIQAiLuAgoMR3Jh",
            "cGhPcHRpb25zEh4KFmVuYWJsZV9yZWN2X3NjaGVkdWxpbmcYAiABKAgSNwoR",
            "b3B0aW1pemVyX29wdGlvbnMYAyABKAsyHC50ZW5zb3JmbG93Lk9wdGltaXpl",
            "ck9wdGlvbnMSGAoQYnVpbGRfY29zdF9tb2RlbBgEIAEoAxIeChZidWlsZF9j",
            "b3N0X21vZGVsX2FmdGVyGAkgASgDEhQKDGluZmVyX3NoYXBlcxgFIAEoCBIa",
            "ChJwbGFjZV9wcnVuZWRfZ3JhcGgYBiABKAgSIAoYZW5hYmxlX2JmbG9hdDE2",
            "X3NlbmRyZWN2GAcgASgIEhUKDXRpbWVsaW5lX3N0ZXAYCCABKAUSMwoPcmV3",
            "cml0ZV9vcHRpb25zGAogASgLMhoudGVuc29yZmxvdy5SZXdyaXRlckNvbmZp",
            "Z0oECAEQAlIlc2tpcF9jb21tb25fc3ViZXhwcmVzc2lvbl9lbGltaW5hdGlv",
            "biJBChVUaHJlYWRQb29sT3B0aW9uUHJvdG8SEwoLbnVtX3RocmVhZHMYASAB",
            "KAUSEwoLZ2xvYmFsX25hbWUYAiABKAkiMgoKUlBDT3B0aW9ucxIkChx1c2Vf",
            "cnBjX2Zvcl9pbnByb2Nlc3NfbWFzdGVyGAEgASgIIp0FCgtDb25maWdQcm90",
            "bxI+CgxkZXZpY2VfY291bnQYASADKAsyKC50ZW5zb3JmbG93LkNvbmZpZ1By",
            "b3RvLkRldmljZUNvdW50RW50cnkSJAocaW50cmFfb3BfcGFyYWxsZWxpc21f",
            "dGhyZWFkcxgCIAEoBRIkChxpbnRlcl9vcF9wYXJhbGxlbGlzbV90aHJlYWRz",
            "GAUgASgFEh8KF3VzZV9wZXJfc2Vzc2lvbl90aHJlYWRzGAkgASgIEkcKHHNl",
            "c3Npb25faW50ZXJfb3BfdGhyZWFkX3Bvb2wYDCADKAsyIS50ZW5zb3JmbG93",
            "LlRocmVhZFBvb2xPcHRpb25Qcm90bxIYChBwbGFjZW1lbnRfcGVyaW9kGAMg",
            "ASgFEhYKDmRldmljZV9maWx0ZXJzGAQgAygJEisKC2dwdV9vcHRpb25zGAYg",
            "ASgLMhYudGVuc29yZmxvdy5HUFVPcHRpb25zEhwKFGFsbG93X3NvZnRfcGxh",
            "Y2VtZW50GAcgASgIEhwKFGxvZ19kZXZpY2VfcGxhY2VtZW50GAggASgIEi8K",
            "DWdyYXBoX29wdGlvbnMYCiABKAsyGC50ZW5zb3JmbG93LkdyYXBoT3B0aW9u",
            "cxIfChdvcGVyYXRpb25fdGltZW91dF9pbl9tcxgLIAEoAxIrCgtycGNfb3B0",
            "aW9ucxgNIAEoCzIWLnRlbnNvcmZsb3cuUlBDT3B0aW9ucxIrCgtjbHVzdGVy",
            "X2RlZhgOIAEoCzIWLnRlbnNvcmZsb3cuQ2x1c3RlckRlZhIdChVpc29sYXRl",
            "X3Nlc3Npb25fc3RhdGUYDyABKAgaMgoQRGV2aWNlQ291bnRFbnRyeRILCgNr",
            "ZXkYASABKAkSDQoFdmFsdWUYAiABKAU6AjgBItECCgpSdW5PcHRpb25zEjYK",
            "C3RyYWNlX2xldmVsGAEgASgOMiEudGVuc29yZmxvdy5SdW5PcHRpb25zLlRy",
            "YWNlTGV2ZWwSFQoNdGltZW91dF9pbl9tcxgCIAEoAxIcChRpbnRlcl9vcF90",
            "aHJlYWRfcG9vbBgDIAEoBRIfChdvdXRwdXRfcGFydGl0aW9uX2dyYXBocxgF",
            "IAEoCBIvCg1kZWJ1Z19vcHRpb25zGAYgASgLMhgudGVuc29yZmxvdy5EZWJ1",
            "Z09wdGlvbnMSKgoicmVwb3J0X3RlbnNvcl9hbGxvY2F0aW9uc191cG9uX29v",
            "bRgHIAEoCCJSCgpUcmFjZUxldmVsEgwKCE5PX1RSQUNFEAASEgoOU09GVFdB",
            "UkVfVFJBQ0UQARISCg5IQVJEV0FSRV9UUkFDRRACEg4KCkZVTExfVFJBQ0UQ",
            "A0oECAQQBSKWAQoLUnVuTWV0YWRhdGESKQoKc3RlcF9zdGF0cxgBIAEoCzIV",
            "LnRlbnNvcmZsb3cuU3RlcFN0YXRzEiwKCmNvc3RfZ3JhcGgYAiABKAsyGC50",
            "ZW5zb3JmbG93LkNvc3RHcmFwaERlZhIuChBwYXJ0aXRpb25fZ3JhcGhzGAMg",
            "AygLMhQudGVuc29yZmxvdy5HcmFwaERlZkItChhvcmcudGVuc29yZmxvdy5m",
            "cmFtZXdvcmtCDENvbmZpZ1Byb3Rvc1AB+AEBYgZwcm90bzM="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Vision.Tensorflow.Proto.CostGraphReflection.Descriptor, global::Vision.Tensorflow.Proto.GraphReflection.Descriptor, global::Vision.Tensorflow.Proto.StepStatsReflection.Descriptor, global::Vision.Tensorflow.Proto.DebugReflection.Descriptor, global::Vision.Tensorflow.Proto.ClusterReflection.Descriptor, global::Vision.Tensorflow.Proto.RewriterConfigReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.GPUOptions), global::Vision.Tensorflow.Proto.GPUOptions.Parser, new[]{ "PerProcessGpuMemoryFraction", "AllocatorType", "DeferredDeletionBytes", "AllowGrowth", "VisibleDeviceList", "PollingActiveDelayUsecs", "PollingInactiveDelayMsecs", "ForceGpuCompatible", "Experimental" }, null, null, new pbr::GeneratedClrTypeInfo[] { new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental), global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Parser, new[]{ "VirtualDevices" }, null, null, new pbr::GeneratedClrTypeInfo[] { new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices), global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices.Parser, new[]{ "MemoryLimitMb" }, null, null, null)})}),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.OptimizerOptions), global::Vision.Tensorflow.Proto.OptimizerOptions.Parser, new[]{ "DoCommonSubexpressionElimination", "DoConstantFolding", "MaxFoldedConstantInBytes", "DoFunctionInlining", "OptLevel", "GlobalJitLevel" }, null, new[]{ typeof(global::Vision.Tensorflow.Proto.OptimizerOptions.Types.Level), typeof(global::Vision.Tensorflow.Proto.OptimizerOptions.Types.GlobalJitLevel) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.GraphOptions), global::Vision.Tensorflow.Proto.GraphOptions.Parser, new[]{ "EnableRecvScheduling", "OptimizerOptions", "BuildCostModel", "BuildCostModelAfter", "InferShapes", "PlacePrunedGraph", "EnableBfloat16Sendrecv", "TimelineStep", "RewriteOptions" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.ThreadPoolOptionProto), global::Vision.Tensorflow.Proto.ThreadPoolOptionProto.Parser, new[]{ "NumThreads", "GlobalName" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.RPCOptions), global::Vision.Tensorflow.Proto.RPCOptions.Parser, new[]{ "UseRpcForInprocessMaster" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.ConfigProto), global::Vision.Tensorflow.Proto.ConfigProto.Parser, new[]{ "DeviceCount", "IntraOpParallelismThreads", "InterOpParallelismThreads", "UsePerSessionThreads", "SessionInterOpThreadPool", "PlacementPeriod", "DeviceFilters", "GpuOptions", "AllowSoftPlacement", "LogDevicePlacement", "GraphOptions", "OperationTimeoutInMs", "RpcOptions", "ClusterDef", "IsolateSessionState" }, null, null, new pbr::GeneratedClrTypeInfo[] { null, }),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.RunOptions), global::Vision.Tensorflow.Proto.RunOptions.Parser, new[]{ "TraceLevel", "TimeoutInMs", "InterOpThreadPool", "OutputPartitionGraphs", "DebugOptions", "ReportTensorAllocationsUponOom" }, null, new[]{ typeof(global::Vision.Tensorflow.Proto.RunOptions.Types.TraceLevel) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Vision.Tensorflow.Proto.RunMetadata), global::Vision.Tensorflow.Proto.RunMetadata.Parser, new[]{ "StepStats", "CostGraph", "PartitionGraphs" }, null, null, null)
          }));
    }
    #endregion

  }
  #region Messages
  public sealed partial class GPUOptions : pb::IMessage<GPUOptions> {
    private static readonly pb::MessageParser<GPUOptions> _parser = new pb::MessageParser<GPUOptions>(() => new GPUOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<GPUOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions(GPUOptions other) : this() {
      perProcessGpuMemoryFraction_ = other.perProcessGpuMemoryFraction_;
      allocatorType_ = other.allocatorType_;
      deferredDeletionBytes_ = other.deferredDeletionBytes_;
      allowGrowth_ = other.allowGrowth_;
      visibleDeviceList_ = other.visibleDeviceList_;
      pollingActiveDelayUsecs_ = other.pollingActiveDelayUsecs_;
      pollingInactiveDelayMsecs_ = other.pollingInactiveDelayMsecs_;
      forceGpuCompatible_ = other.forceGpuCompatible_;
      Experimental = other.experimental_ != null ? other.Experimental.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GPUOptions Clone() {
      return new GPUOptions(this);
    }

    /// <summary>Field number for the "per_process_gpu_memory_fraction" field.</summary>
    public const int PerProcessGpuMemoryFractionFieldNumber = 1;
    private double perProcessGpuMemoryFraction_;
    /// <summary>
    /// A value between 0 and 1 that indicates what fraction of the
    /// available GPU memory to pre-allocate for each process.  1 means
    /// to pre-allocate all of the GPU memory, 0.5 means the process
    /// allocates ~50% of the available GPU memory.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double PerProcessGpuMemoryFraction {
      get { return perProcessGpuMemoryFraction_; }
      set {
        perProcessGpuMemoryFraction_ = value;
      }
    }

    /// <summary>Field number for the "allocator_type" field.</summary>
    public const int AllocatorTypeFieldNumber = 2;
    private string allocatorType_ = "";
    /// <summary>
    /// The type of GPU allocation strategy to use.
    ///
    /// Allowed values:
    /// "": The empty string (default) uses a system-chosen default
    ///     which may change over time.
    ///
    /// "BFC": A "Best-fit with coalescing" algorithm, simplified from a
    ///        version of dlmalloc.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string AllocatorType {
      get { return allocatorType_; }
      set {
        allocatorType_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "deferred_deletion_bytes" field.</summary>
    public const int DeferredDeletionBytesFieldNumber = 3;
    private long deferredDeletionBytes_;
    /// <summary>
    /// Delay deletion of up to this many bytes to reduce the number of
    /// interactions with gpu driver code.  If 0, the system chooses
    /// a reasonable default (several MBs).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long DeferredDeletionBytes {
      get { return deferredDeletionBytes_; }
      set {
        deferredDeletionBytes_ = value;
      }
    }

    /// <summary>Field number for the "allow_growth" field.</summary>
    public const int AllowGrowthFieldNumber = 4;
    private bool allowGrowth_;
    /// <summary>
    /// If true, the allocator does not pre-allocate the entire specified
    /// GPU memory region, instead starting small and growing as needed.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool AllowGrowth {
      get { return allowGrowth_; }
      set {
        allowGrowth_ = value;
      }
    }

    /// <summary>Field number for the "visible_device_list" field.</summary>
    public const int VisibleDeviceListFieldNumber = 5;
    private string visibleDeviceList_ = "";
    /// <summary>
    /// A comma-separated list of GPU ids that determines the 'visible'
    /// to 'virtual' mapping of GPU devices.  For example, if TensorFlow
    /// can see 8 GPU devices in the process, and one wanted to map
    /// visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
    /// then one would specify this field as "5,3".  This field is similar in
    /// spirit to the CUDA_VISIBLE_DEVICES environment variable, except
    /// it applies to the visible GPU devices in the process.
    ///
    /// NOTE:
    /// 1. The GPU driver provides the process with the visible GPUs
    ///    in an order which is not guaranteed to have any correlation to
    ///    the *physical* GPU id in the machine.  This field is used for
    ///    remapping "visible" to "virtual", which means this operates only
    ///    after the process starts.  Users are required to use vendor
    ///    specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
    ///    physical to visible device mapping prior to invoking TensorFlow.
    /// 2. In the code, the ids in this list are also called "CUDA GPU id"s,
    ///    and the 'virtual' ids of GPU devices (i.e. the ids in the device
    ///    name "/device:GPU:&lt;id>") are also called "TF GPU id"s. Please
    ///    refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
    ///    for more information.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string VisibleDeviceList {
      get { return visibleDeviceList_; }
      set {
        visibleDeviceList_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "polling_active_delay_usecs" field.</summary>
    public const int PollingActiveDelayUsecsFieldNumber = 6;
    private int pollingActiveDelayUsecs_;
    /// <summary>
    /// In the event polling loop sleep this many microseconds between
    /// PollEvents calls, when the queue is not empty.  If value is not
    /// set or set to 0, gets set to a non-zero default.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PollingActiveDelayUsecs {
      get { return pollingActiveDelayUsecs_; }
      set {
        pollingActiveDelayUsecs_ = value;
      }
    }

    /// <summary>Field number for the "polling_inactive_delay_msecs" field.</summary>
    public const int PollingInactiveDelayMsecsFieldNumber = 7;
    private int pollingInactiveDelayMsecs_;
    /// <summary>
    /// In the event polling loop sleep this many millisconds between
    /// PollEvents calls, when the queue is empty.  If value is not
    /// set or set to 0, gets set to a non-zero default.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PollingInactiveDelayMsecs {
      get { return pollingInactiveDelayMsecs_; }
      set {
        pollingInactiveDelayMsecs_ = value;
      }
    }

    /// <summary>Field number for the "force_gpu_compatible" field.</summary>
    public const int ForceGpuCompatibleFieldNumber = 8;
    private bool forceGpuCompatible_;
    /// <summary>
    /// Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
    /// enabling this option forces all CPU tensors to be allocated with Cuda
    /// pinned memory. Normally, TensorFlow will infer which tensors should be
    /// allocated as the pinned memory. But in case where the inference is
    /// incomplete, this option can significantly speed up the cross-device memory
    /// copy performance as long as it fits the memory.
    /// Note that this option is not something that should be
    /// enabled by default for unknown or very large models, since all Cuda pinned
    /// memory is unpageable, having too much pinned memory might negatively impact
    /// the overall host system performance.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ForceGpuCompatible {
      get { return forceGpuCompatible_; }
      set {
        forceGpuCompatible_ = value;
      }
    }

    /// <summary>Field number for the "experimental" field.</summary>
    public const int ExperimentalFieldNumber = 9;
    private global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental experimental_;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental Experimental {
      get { return experimental_; }
      set {
        experimental_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as GPUOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(GPUOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (PerProcessGpuMemoryFraction != other.PerProcessGpuMemoryFraction) return false;
      if (AllocatorType != other.AllocatorType) return false;
      if (DeferredDeletionBytes != other.DeferredDeletionBytes) return false;
      if (AllowGrowth != other.AllowGrowth) return false;
      if (VisibleDeviceList != other.VisibleDeviceList) return false;
      if (PollingActiveDelayUsecs != other.PollingActiveDelayUsecs) return false;
      if (PollingInactiveDelayMsecs != other.PollingInactiveDelayMsecs) return false;
      if (ForceGpuCompatible != other.ForceGpuCompatible) return false;
      if (!object.Equals(Experimental, other.Experimental)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (PerProcessGpuMemoryFraction != 0D) hash ^= PerProcessGpuMemoryFraction.GetHashCode();
      if (AllocatorType.Length != 0) hash ^= AllocatorType.GetHashCode();
      if (DeferredDeletionBytes != 0L) hash ^= DeferredDeletionBytes.GetHashCode();
      if (AllowGrowth != false) hash ^= AllowGrowth.GetHashCode();
      if (VisibleDeviceList.Length != 0) hash ^= VisibleDeviceList.GetHashCode();
      if (PollingActiveDelayUsecs != 0) hash ^= PollingActiveDelayUsecs.GetHashCode();
      if (PollingInactiveDelayMsecs != 0) hash ^= PollingInactiveDelayMsecs.GetHashCode();
      if (ForceGpuCompatible != false) hash ^= ForceGpuCompatible.GetHashCode();
      if (experimental_ != null) hash ^= Experimental.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (PerProcessGpuMemoryFraction != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(PerProcessGpuMemoryFraction);
      }
      if (AllocatorType.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(AllocatorType);
      }
      if (DeferredDeletionBytes != 0L) {
        output.WriteRawTag(24);
        output.WriteInt64(DeferredDeletionBytes);
      }
      if (AllowGrowth != false) {
        output.WriteRawTag(32);
        output.WriteBool(AllowGrowth);
      }
      if (VisibleDeviceList.Length != 0) {
        output.WriteRawTag(42);
        output.WriteString(VisibleDeviceList);
      }
      if (PollingActiveDelayUsecs != 0) {
        output.WriteRawTag(48);
        output.WriteInt32(PollingActiveDelayUsecs);
      }
      if (PollingInactiveDelayMsecs != 0) {
        output.WriteRawTag(56);
        output.WriteInt32(PollingInactiveDelayMsecs);
      }
      if (ForceGpuCompatible != false) {
        output.WriteRawTag(64);
        output.WriteBool(ForceGpuCompatible);
      }
      if (experimental_ != null) {
        output.WriteRawTag(74);
        output.WriteMessage(Experimental);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (PerProcessGpuMemoryFraction != 0D) {
        size += 1 + 8;
      }
      if (AllocatorType.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(AllocatorType);
      }
      if (DeferredDeletionBytes != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(DeferredDeletionBytes);
      }
      if (AllowGrowth != false) {
        size += 1 + 1;
      }
      if (VisibleDeviceList.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(VisibleDeviceList);
      }
      if (PollingActiveDelayUsecs != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PollingActiveDelayUsecs);
      }
      if (PollingInactiveDelayMsecs != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PollingInactiveDelayMsecs);
      }
      if (ForceGpuCompatible != false) {
        size += 1 + 1;
      }
      if (experimental_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Experimental);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(GPUOptions other) {
      if (other == null) {
        return;
      }
      if (other.PerProcessGpuMemoryFraction != 0D) {
        PerProcessGpuMemoryFraction = other.PerProcessGpuMemoryFraction;
      }
      if (other.AllocatorType.Length != 0) {
        AllocatorType = other.AllocatorType;
      }
      if (other.DeferredDeletionBytes != 0L) {
        DeferredDeletionBytes = other.DeferredDeletionBytes;
      }
      if (other.AllowGrowth != false) {
        AllowGrowth = other.AllowGrowth;
      }
      if (other.VisibleDeviceList.Length != 0) {
        VisibleDeviceList = other.VisibleDeviceList;
      }
      if (other.PollingActiveDelayUsecs != 0) {
        PollingActiveDelayUsecs = other.PollingActiveDelayUsecs;
      }
      if (other.PollingInactiveDelayMsecs != 0) {
        PollingInactiveDelayMsecs = other.PollingInactiveDelayMsecs;
      }
      if (other.ForceGpuCompatible != false) {
        ForceGpuCompatible = other.ForceGpuCompatible;
      }
      if (other.experimental_ != null) {
        if (experimental_ == null) {
          experimental_ = new global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental();
        }
        Experimental.MergeFrom(other.Experimental);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 9: {
            PerProcessGpuMemoryFraction = input.ReadDouble();
            break;
          }
          case 18: {
            AllocatorType = input.ReadString();
            break;
          }
          case 24: {
            DeferredDeletionBytes = input.ReadInt64();
            break;
          }
          case 32: {
            AllowGrowth = input.ReadBool();
            break;
          }
          case 42: {
            VisibleDeviceList = input.ReadString();
            break;
          }
          case 48: {
            PollingActiveDelayUsecs = input.ReadInt32();
            break;
          }
          case 56: {
            PollingInactiveDelayMsecs = input.ReadInt32();
            break;
          }
          case 64: {
            ForceGpuCompatible = input.ReadBool();
            break;
          }
          case 74: {
            if (experimental_ == null) {
              experimental_ = new global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental();
            }
            input.ReadMessage(experimental_);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the GPUOptions message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Everything inside Experimental is subject to change and is not subject
      /// to API stability guarantees in
      /// https://www.tensorflow.org/programmers_guide/version_compat.
      /// </summary>
      public sealed partial class Experimental : pb::IMessage<Experimental> {
        private static readonly pb::MessageParser<Experimental> _parser = new pb::MessageParser<Experimental>(() => new Experimental());
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public static pb::MessageParser<Experimental> Parser { get { return _parser; } }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public static pbr::MessageDescriptor Descriptor {
          get { return global::Vision.Tensorflow.Proto.GPUOptions.Descriptor.NestedTypes[0]; }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        pbr::MessageDescriptor pb::IMessage.Descriptor {
          get { return Descriptor; }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public Experimental() {
          OnConstruction();
        }

        partial void OnConstruction();

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public Experimental(Experimental other) : this() {
          virtualDevices_ = other.virtualDevices_.Clone();
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public Experimental Clone() {
          return new Experimental(this);
        }

        /// <summary>Field number for the "virtual_devices" field.</summary>
        public const int VirtualDevicesFieldNumber = 1;
        private static readonly pb::FieldCodec<global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices> _repeated_virtualDevices_codec
            = pb::FieldCodec.ForMessage(10, global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices.Parser);
        private readonly pbc::RepeatedField<global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices> virtualDevices_ = new pbc::RepeatedField<global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices>();
        /// <summary>
        /// The multi virtual device settings. If empty (not set), it will create
        /// single virtual device on each visible GPU, according to the settings
        /// in "visible_device_list" above. Otherwise, the number of elements in the
        /// list must be the same as the number of visible GPUs (after
        /// "visible_device_list" filtering if it is set), and the string represented
        /// device names (e.g. /device:GPU:&lt;id>) will refer to the virtual
        /// devices and have the &lt;id> field assigned sequentially starting from 0,
        /// according to the order they appear in this list and the "memory_limit"
        /// list inside each element. For example,
        ///   visible_device_list = "1,0"
        ///   virtual_devices { memory_limit: 1GB memory_limit: 2GB }
        ///   virtual_devices {}
        /// will create three virtual devices as:
        ///   /device:GPU:0 -> visible GPU 1 with 1GB memory
        ///   /device:GPU:1 -> visible GPU 1 with 2GB memory
        ///   /device:GPU:2 -> visible GPU 0 with all available memory
        ///
        /// NOTE:
        /// 1. It's invalid to set both this and "per_process_gpu_memory_fraction"
        ///    at the same time.
        /// 2. Currently this setting is per-process, not per-session. Using
        ///    different settings in different sessions within same process will
        ///    result in undefined behavior.
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public pbc::RepeatedField<global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Types.VirtualDevices> VirtualDevices {
          get { return virtualDevices_; }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override bool Equals(object other) {
          return Equals(other as Experimental);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public bool Equals(Experimental other) {
          if (ReferenceEquals(other, null)) {
            return false;
          }
          if (ReferenceEquals(other, this)) {
            return true;
          }
          if(!virtualDevices_.Equals(other.virtualDevices_)) return false;
          return true;
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override int GetHashCode() {
          int hash = 1;
          hash ^= virtualDevices_.GetHashCode();
          return hash;
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override string ToString() {
          return pb::JsonFormatter.ToDiagnosticString(this);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void WriteTo(pb::CodedOutputStream output) {
          virtualDevices_.WriteTo(output, _repeated_virtualDevices_codec);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public int CalculateSize() {
          int size = 0;
          size += virtualDevices_.CalculateSize(_repeated_virtualDevices_codec);
          return size;
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void MergeFrom(Experimental other) {
          if (other == null) {
            return;
          }
          virtualDevices_.Add(other.virtualDevices_);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void MergeFrom(pb::CodedInputStream input) {
          uint tag;
          while ((tag = input.ReadTag()) != 0) {
            switch(tag) {
              default:
                input.SkipLastField();
                break;
              case 10: {
                virtualDevices_.AddEntriesFrom(input, _repeated_virtualDevices_codec);
                break;
              }
            }
          }
        }

        #region Nested types
        /// <summary>Container for nested types declared in the Experimental message type.</summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public static partial class Types {
          /// <summary>
          /// Configuration for breaking down a visible GPU into multiple "virtual"
          /// devices.
          /// </summary>
          public sealed partial class VirtualDevices : pb::IMessage<VirtualDevices> {
            private static readonly pb::MessageParser<VirtualDevices> _parser = new pb::MessageParser<VirtualDevices>(() => new VirtualDevices());
            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public static pb::MessageParser<VirtualDevices> Parser { get { return _parser; } }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public static pbr::MessageDescriptor Descriptor {
              get { return global::Vision.Tensorflow.Proto.GPUOptions.Types.Experimental.Descriptor.NestedTypes[0]; }
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            pbr::MessageDescriptor pb::IMessage.Descriptor {
              get { return Descriptor; }
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public VirtualDevices() {
              OnConstruction();
            }

            partial void OnConstruction();

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public VirtualDevices(VirtualDevices other) : this() {
              memoryLimitMb_ = other.memoryLimitMb_.Clone();
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public VirtualDevices Clone() {
              return new VirtualDevices(this);
            }

            /// <summary>Field number for the "memory_limit_mb" field.</summary>
            public const int MemoryLimitMbFieldNumber = 1;
            private static readonly pb::FieldCodec<float> _repeated_memoryLimitMb_codec
                = pb::FieldCodec.ForFloat(10);
            private readonly pbc::RepeatedField<float> memoryLimitMb_ = new pbc::RepeatedField<float>();
            /// <summary>
            /// Per "virtual" device memory limit, in MB. The number of elements in
            /// the list is the number of virtual devices to create on the
            /// corresponding visible GPU (see "virtual_devices" below).
            /// If empty, it will create single virtual device taking all available
            /// memory from the device.
            ///
            /// For the concept of "visible" and "virtual" GPU, see the comments for
            /// "visible_device_list" above for more information.
            /// </summary>
            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public pbc::RepeatedField<float> MemoryLimitMb {
              get { return memoryLimitMb_; }
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public override bool Equals(object other) {
              return Equals(other as VirtualDevices);
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public bool Equals(VirtualDevices other) {
              if (ReferenceEquals(other, null)) {
                return false;
              }
              if (ReferenceEquals(other, this)) {
                return true;
              }
              if(!memoryLimitMb_.Equals(other.memoryLimitMb_)) return false;
              return true;
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public override int GetHashCode() {
              int hash = 1;
              hash ^= memoryLimitMb_.GetHashCode();
              return hash;
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public override string ToString() {
              return pb::JsonFormatter.ToDiagnosticString(this);
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public void WriteTo(pb::CodedOutputStream output) {
              memoryLimitMb_.WriteTo(output, _repeated_memoryLimitMb_codec);
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public int CalculateSize() {
              int size = 0;
              size += memoryLimitMb_.CalculateSize(_repeated_memoryLimitMb_codec);
              return size;
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public void MergeFrom(VirtualDevices other) {
              if (other == null) {
                return;
              }
              memoryLimitMb_.Add(other.memoryLimitMb_);
            }

            [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
            public void MergeFrom(pb::CodedInputStream input) {
              uint tag;
              while ((tag = input.ReadTag()) != 0) {
                switch(tag) {
                  default:
                    input.SkipLastField();
                    break;
                  case 10:
                  case 13: {
                    memoryLimitMb_.AddEntriesFrom(input, _repeated_memoryLimitMb_codec);
                    break;
                  }
                }
              }
            }

          }

        }
        #endregion

      }

    }
    #endregion

  }

  /// <summary>
  /// Options passed to the graph optimizer
  /// </summary>
  public sealed partial class OptimizerOptions : pb::IMessage<OptimizerOptions> {
    private static readonly pb::MessageParser<OptimizerOptions> _parser = new pb::MessageParser<OptimizerOptions>(() => new OptimizerOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<OptimizerOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions(OptimizerOptions other) : this() {
      doCommonSubexpressionElimination_ = other.doCommonSubexpressionElimination_;
      doConstantFolding_ = other.doConstantFolding_;
      maxFoldedConstantInBytes_ = other.maxFoldedConstantInBytes_;
      doFunctionInlining_ = other.doFunctionInlining_;
      optLevel_ = other.optLevel_;
      globalJitLevel_ = other.globalJitLevel_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OptimizerOptions Clone() {
      return new OptimizerOptions(this);
    }

    /// <summary>Field number for the "do_common_subexpression_elimination" field.</summary>
    public const int DoCommonSubexpressionEliminationFieldNumber = 1;
    private bool doCommonSubexpressionElimination_;
    /// <summary>
    /// If true, optimize the graph using common subexpression elimination.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoCommonSubexpressionElimination {
      get { return doCommonSubexpressionElimination_; }
      set {
        doCommonSubexpressionElimination_ = value;
      }
    }

    /// <summary>Field number for the "do_constant_folding" field.</summary>
    public const int DoConstantFoldingFieldNumber = 2;
    private bool doConstantFolding_;
    /// <summary>
    /// If true, perform constant folding optimization on the graph.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoConstantFolding {
      get { return doConstantFolding_; }
      set {
        doConstantFolding_ = value;
      }
    }

    /// <summary>Field number for the "max_folded_constant_in_bytes" field.</summary>
    public const int MaxFoldedConstantInBytesFieldNumber = 6;
    private long maxFoldedConstantInBytes_;
    /// <summary>
    /// Constant folding optimization replaces tensors whose values can be
    /// predetermined, with constant nodes. To avoid inserting too large constants,
    /// the size of each constant created can be limited. If this value is zero, a
    /// default limit of 10 MiB will be applied. If constant folding optimization
    /// is disabled, this value is ignored.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long MaxFoldedConstantInBytes {
      get { return maxFoldedConstantInBytes_; }
      set {
        maxFoldedConstantInBytes_ = value;
      }
    }

    /// <summary>Field number for the "do_function_inlining" field.</summary>
    public const int DoFunctionInliningFieldNumber = 4;
    private bool doFunctionInlining_;
    /// <summary>
    /// If true, perform function inlining on the graph.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool DoFunctionInlining {
      get { return doFunctionInlining_; }
      set {
        doFunctionInlining_ = value;
      }
    }

    /// <summary>Field number for the "opt_level" field.</summary>
    public const int OptLevelFieldNumber = 3;
    private global::Vision.Tensorflow.Proto.OptimizerOptions.Types.Level optLevel_ = 0;
    /// <summary>
    /// Overall optimization level. The actual optimizations applied will be the
    /// logical OR of the flags that this level implies and any flags already set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.OptimizerOptions.Types.Level OptLevel {
      get { return optLevel_; }
      set {
        optLevel_ = value;
      }
    }

    /// <summary>Field number for the "global_jit_level" field.</summary>
    public const int GlobalJitLevelFieldNumber = 5;
    private global::Vision.Tensorflow.Proto.OptimizerOptions.Types.GlobalJitLevel globalJitLevel_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.OptimizerOptions.Types.GlobalJitLevel GlobalJitLevel {
      get { return globalJitLevel_; }
      set {
        globalJitLevel_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as OptimizerOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(OptimizerOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (DoCommonSubexpressionElimination != other.DoCommonSubexpressionElimination) return false;
      if (DoConstantFolding != other.DoConstantFolding) return false;
      if (MaxFoldedConstantInBytes != other.MaxFoldedConstantInBytes) return false;
      if (DoFunctionInlining != other.DoFunctionInlining) return false;
      if (OptLevel != other.OptLevel) return false;
      if (GlobalJitLevel != other.GlobalJitLevel) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (DoCommonSubexpressionElimination != false) hash ^= DoCommonSubexpressionElimination.GetHashCode();
      if (DoConstantFolding != false) hash ^= DoConstantFolding.GetHashCode();
      if (MaxFoldedConstantInBytes != 0L) hash ^= MaxFoldedConstantInBytes.GetHashCode();
      if (DoFunctionInlining != false) hash ^= DoFunctionInlining.GetHashCode();
      if (OptLevel != 0) hash ^= OptLevel.GetHashCode();
      if (GlobalJitLevel != 0) hash ^= GlobalJitLevel.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (DoCommonSubexpressionElimination != false) {
        output.WriteRawTag(8);
        output.WriteBool(DoCommonSubexpressionElimination);
      }
      if (DoConstantFolding != false) {
        output.WriteRawTag(16);
        output.WriteBool(DoConstantFolding);
      }
      if (OptLevel != 0) {
        output.WriteRawTag(24);
        output.WriteEnum((int) OptLevel);
      }
      if (DoFunctionInlining != false) {
        output.WriteRawTag(32);
        output.WriteBool(DoFunctionInlining);
      }
      if (GlobalJitLevel != 0) {
        output.WriteRawTag(40);
        output.WriteEnum((int) GlobalJitLevel);
      }
      if (MaxFoldedConstantInBytes != 0L) {
        output.WriteRawTag(48);
        output.WriteInt64(MaxFoldedConstantInBytes);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (DoCommonSubexpressionElimination != false) {
        size += 1 + 1;
      }
      if (DoConstantFolding != false) {
        size += 1 + 1;
      }
      if (MaxFoldedConstantInBytes != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(MaxFoldedConstantInBytes);
      }
      if (DoFunctionInlining != false) {
        size += 1 + 1;
      }
      if (OptLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) OptLevel);
      }
      if (GlobalJitLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) GlobalJitLevel);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(OptimizerOptions other) {
      if (other == null) {
        return;
      }
      if (other.DoCommonSubexpressionElimination != false) {
        DoCommonSubexpressionElimination = other.DoCommonSubexpressionElimination;
      }
      if (other.DoConstantFolding != false) {
        DoConstantFolding = other.DoConstantFolding;
      }
      if (other.MaxFoldedConstantInBytes != 0L) {
        MaxFoldedConstantInBytes = other.MaxFoldedConstantInBytes;
      }
      if (other.DoFunctionInlining != false) {
        DoFunctionInlining = other.DoFunctionInlining;
      }
      if (other.OptLevel != 0) {
        OptLevel = other.OptLevel;
      }
      if (other.GlobalJitLevel != 0) {
        GlobalJitLevel = other.GlobalJitLevel;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            DoCommonSubexpressionElimination = input.ReadBool();
            break;
          }
          case 16: {
            DoConstantFolding = input.ReadBool();
            break;
          }
          case 24: {
            optLevel_ = (global::Vision.Tensorflow.Proto.OptimizerOptions.Types.Level) input.ReadEnum();
            break;
          }
          case 32: {
            DoFunctionInlining = input.ReadBool();
            break;
          }
          case 40: {
            globalJitLevel_ = (global::Vision.Tensorflow.Proto.OptimizerOptions.Types.GlobalJitLevel) input.ReadEnum();
            break;
          }
          case 48: {
            MaxFoldedConstantInBytes = input.ReadInt64();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the OptimizerOptions message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Optimization level
      /// </summary>
      public enum Level {
        /// <summary>
        /// L1 is the default level.
        /// Optimization performed at L1 :
        /// 1. Common subexpression elimination
        /// 2. Constant folding
        /// </summary>
        [pbr::OriginalName("L1")] L1 = 0,
        /// <summary>
        /// No optimizations
        /// </summary>
        [pbr::OriginalName("L0")] L0 = -1,
      }

      /// <summary>
      /// Control the use of the compiler/jit.  Experimental.
      /// </summary>
      public enum GlobalJitLevel {
        /// <summary>
        /// Default setting ("off" now, but later expected to be "on")
        /// </summary>
        [pbr::OriginalName("DEFAULT")] Default = 0,
        [pbr::OriginalName("OFF")] Off = -1,
        /// <summary>
        /// The following settings turn on compilation, with higher values being
        /// more aggressive.  Higher values may reduce opportunities for parallelism
        /// and may use more memory.  (At present, there is no distinction, but this
        /// is expected to change.)
        /// </summary>
        [pbr::OriginalName("ON_1")] On1 = 1,
        [pbr::OriginalName("ON_2")] On2 = 2,
      }

    }
    #endregion

  }

  public sealed partial class GraphOptions : pb::IMessage<GraphOptions> {
    private static readonly pb::MessageParser<GraphOptions> _parser = new pb::MessageParser<GraphOptions>(() => new GraphOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<GraphOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions(GraphOptions other) : this() {
      enableRecvScheduling_ = other.enableRecvScheduling_;
      OptimizerOptions = other.optimizerOptions_ != null ? other.OptimizerOptions.Clone() : null;
      buildCostModel_ = other.buildCostModel_;
      buildCostModelAfter_ = other.buildCostModelAfter_;
      inferShapes_ = other.inferShapes_;
      placePrunedGraph_ = other.placePrunedGraph_;
      enableBfloat16Sendrecv_ = other.enableBfloat16Sendrecv_;
      timelineStep_ = other.timelineStep_;
      RewriteOptions = other.rewriteOptions_ != null ? other.RewriteOptions.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public GraphOptions Clone() {
      return new GraphOptions(this);
    }

    /// <summary>Field number for the "enable_recv_scheduling" field.</summary>
    public const int EnableRecvSchedulingFieldNumber = 2;
    private bool enableRecvScheduling_;
    /// <summary>
    /// If true, use control flow to schedule the activation of Recv nodes.
    /// (Currently ignored.)
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableRecvScheduling {
      get { return enableRecvScheduling_; }
      set {
        enableRecvScheduling_ = value;
      }
    }

    /// <summary>Field number for the "optimizer_options" field.</summary>
    public const int OptimizerOptionsFieldNumber = 3;
    private global::Vision.Tensorflow.Proto.OptimizerOptions optimizerOptions_;
    /// <summary>
    /// Options controlling how graph is optimized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.OptimizerOptions OptimizerOptions {
      get { return optimizerOptions_; }
      set {
        optimizerOptions_ = value;
      }
    }

    /// <summary>Field number for the "build_cost_model" field.</summary>
    public const int BuildCostModelFieldNumber = 4;
    private long buildCostModel_;
    /// <summary>
    /// The number of steps to run before returning a cost model detailing
    /// the memory usage and performance of each node of the graph. 0 means
    /// no cost model.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long BuildCostModel {
      get { return buildCostModel_; }
      set {
        buildCostModel_ = value;
      }
    }

    /// <summary>Field number for the "build_cost_model_after" field.</summary>
    public const int BuildCostModelAfterFieldNumber = 9;
    private long buildCostModelAfter_;
    /// <summary>
    /// The number of steps to skip before collecting statistics for the
    /// cost model.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long BuildCostModelAfter {
      get { return buildCostModelAfter_; }
      set {
        buildCostModelAfter_ = value;
      }
    }

    /// <summary>Field number for the "infer_shapes" field.</summary>
    public const int InferShapesFieldNumber = 5;
    private bool inferShapes_;
    /// <summary>
    /// Annotate each Node with Op output shape data, to the extent it can
    /// be statically inferred.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool InferShapes {
      get { return inferShapes_; }
      set {
        inferShapes_ = value;
      }
    }

    /// <summary>Field number for the "place_pruned_graph" field.</summary>
    public const int PlacePrunedGraphFieldNumber = 6;
    private bool placePrunedGraph_;
    /// <summary>
    /// Only place the subgraphs that are run, rather than the entire graph.
    ///
    /// This is useful for interactive graph building, where one might
    /// produce graphs that cannot be placed during the debugging
    /// process.  In particular, it allows the client to continue work in
    /// a session after adding a node to a graph whose placement
    /// constraints are unsatisfiable.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool PlacePrunedGraph {
      get { return placePrunedGraph_; }
      set {
        placePrunedGraph_ = value;
      }
    }

    /// <summary>Field number for the "enable_bfloat16_sendrecv" field.</summary>
    public const int EnableBfloat16SendrecvFieldNumber = 7;
    private bool enableBfloat16Sendrecv_;
    /// <summary>
    /// If true, transfer float values between processes as bfloat16.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool EnableBfloat16Sendrecv {
      get { return enableBfloat16Sendrecv_; }
      set {
        enableBfloat16Sendrecv_ = value;
      }
    }

    /// <summary>Field number for the "timeline_step" field.</summary>
    public const int TimelineStepFieldNumber = 8;
    private int timelineStep_;
    /// <summary>
    /// If > 0, record a timeline every this many steps.
    /// EXPERIMENTAL: This currently has no effect in MasterSession.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int TimelineStep {
      get { return timelineStep_; }
      set {
        timelineStep_ = value;
      }
    }

    /// <summary>Field number for the "rewrite_options" field.</summary>
    public const int RewriteOptionsFieldNumber = 10;
    private global::Vision.Tensorflow.Proto.RewriterConfig rewriteOptions_;
    /// <summary>
    /// Options that control the type and amount of graph rewriting.
    /// Not currently configurable via the public Python API (i.e. there is no API
    /// stability guarantee if you import RewriterConfig explicitly).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.RewriterConfig RewriteOptions {
      get { return rewriteOptions_; }
      set {
        rewriteOptions_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as GraphOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(GraphOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (EnableRecvScheduling != other.EnableRecvScheduling) return false;
      if (!object.Equals(OptimizerOptions, other.OptimizerOptions)) return false;
      if (BuildCostModel != other.BuildCostModel) return false;
      if (BuildCostModelAfter != other.BuildCostModelAfter) return false;
      if (InferShapes != other.InferShapes) return false;
      if (PlacePrunedGraph != other.PlacePrunedGraph) return false;
      if (EnableBfloat16Sendrecv != other.EnableBfloat16Sendrecv) return false;
      if (TimelineStep != other.TimelineStep) return false;
      if (!object.Equals(RewriteOptions, other.RewriteOptions)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (EnableRecvScheduling != false) hash ^= EnableRecvScheduling.GetHashCode();
      if (optimizerOptions_ != null) hash ^= OptimizerOptions.GetHashCode();
      if (BuildCostModel != 0L) hash ^= BuildCostModel.GetHashCode();
      if (BuildCostModelAfter != 0L) hash ^= BuildCostModelAfter.GetHashCode();
      if (InferShapes != false) hash ^= InferShapes.GetHashCode();
      if (PlacePrunedGraph != false) hash ^= PlacePrunedGraph.GetHashCode();
      if (EnableBfloat16Sendrecv != false) hash ^= EnableBfloat16Sendrecv.GetHashCode();
      if (TimelineStep != 0) hash ^= TimelineStep.GetHashCode();
      if (rewriteOptions_ != null) hash ^= RewriteOptions.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (EnableRecvScheduling != false) {
        output.WriteRawTag(16);
        output.WriteBool(EnableRecvScheduling);
      }
      if (optimizerOptions_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(OptimizerOptions);
      }
      if (BuildCostModel != 0L) {
        output.WriteRawTag(32);
        output.WriteInt64(BuildCostModel);
      }
      if (InferShapes != false) {
        output.WriteRawTag(40);
        output.WriteBool(InferShapes);
      }
      if (PlacePrunedGraph != false) {
        output.WriteRawTag(48);
        output.WriteBool(PlacePrunedGraph);
      }
      if (EnableBfloat16Sendrecv != false) {
        output.WriteRawTag(56);
        output.WriteBool(EnableBfloat16Sendrecv);
      }
      if (TimelineStep != 0) {
        output.WriteRawTag(64);
        output.WriteInt32(TimelineStep);
      }
      if (BuildCostModelAfter != 0L) {
        output.WriteRawTag(72);
        output.WriteInt64(BuildCostModelAfter);
      }
      if (rewriteOptions_ != null) {
        output.WriteRawTag(82);
        output.WriteMessage(RewriteOptions);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (EnableRecvScheduling != false) {
        size += 1 + 1;
      }
      if (optimizerOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(OptimizerOptions);
      }
      if (BuildCostModel != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(BuildCostModel);
      }
      if (BuildCostModelAfter != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(BuildCostModelAfter);
      }
      if (InferShapes != false) {
        size += 1 + 1;
      }
      if (PlacePrunedGraph != false) {
        size += 1 + 1;
      }
      if (EnableBfloat16Sendrecv != false) {
        size += 1 + 1;
      }
      if (TimelineStep != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(TimelineStep);
      }
      if (rewriteOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(RewriteOptions);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(GraphOptions other) {
      if (other == null) {
        return;
      }
      if (other.EnableRecvScheduling != false) {
        EnableRecvScheduling = other.EnableRecvScheduling;
      }
      if (other.optimizerOptions_ != null) {
        if (optimizerOptions_ == null) {
          optimizerOptions_ = new global::Vision.Tensorflow.Proto.OptimizerOptions();
        }
        OptimizerOptions.MergeFrom(other.OptimizerOptions);
      }
      if (other.BuildCostModel != 0L) {
        BuildCostModel = other.BuildCostModel;
      }
      if (other.BuildCostModelAfter != 0L) {
        BuildCostModelAfter = other.BuildCostModelAfter;
      }
      if (other.InferShapes != false) {
        InferShapes = other.InferShapes;
      }
      if (other.PlacePrunedGraph != false) {
        PlacePrunedGraph = other.PlacePrunedGraph;
      }
      if (other.EnableBfloat16Sendrecv != false) {
        EnableBfloat16Sendrecv = other.EnableBfloat16Sendrecv;
      }
      if (other.TimelineStep != 0) {
        TimelineStep = other.TimelineStep;
      }
      if (other.rewriteOptions_ != null) {
        if (rewriteOptions_ == null) {
          rewriteOptions_ = new global::Vision.Tensorflow.Proto.RewriterConfig();
        }
        RewriteOptions.MergeFrom(other.RewriteOptions);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 16: {
            EnableRecvScheduling = input.ReadBool();
            break;
          }
          case 26: {
            if (optimizerOptions_ == null) {
              optimizerOptions_ = new global::Vision.Tensorflow.Proto.OptimizerOptions();
            }
            input.ReadMessage(optimizerOptions_);
            break;
          }
          case 32: {
            BuildCostModel = input.ReadInt64();
            break;
          }
          case 40: {
            InferShapes = input.ReadBool();
            break;
          }
          case 48: {
            PlacePrunedGraph = input.ReadBool();
            break;
          }
          case 56: {
            EnableBfloat16Sendrecv = input.ReadBool();
            break;
          }
          case 64: {
            TimelineStep = input.ReadInt32();
            break;
          }
          case 72: {
            BuildCostModelAfter = input.ReadInt64();
            break;
          }
          case 82: {
            if (rewriteOptions_ == null) {
              rewriteOptions_ = new global::Vision.Tensorflow.Proto.RewriterConfig();
            }
            input.ReadMessage(rewriteOptions_);
            break;
          }
        }
      }
    }

  }

  public sealed partial class ThreadPoolOptionProto : pb::IMessage<ThreadPoolOptionProto> {
    private static readonly pb::MessageParser<ThreadPoolOptionProto> _parser = new pb::MessageParser<ThreadPoolOptionProto>(() => new ThreadPoolOptionProto());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ThreadPoolOptionProto> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto(ThreadPoolOptionProto other) : this() {
      numThreads_ = other.numThreads_;
      globalName_ = other.globalName_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ThreadPoolOptionProto Clone() {
      return new ThreadPoolOptionProto(this);
    }

    /// <summary>Field number for the "num_threads" field.</summary>
    public const int NumThreadsFieldNumber = 1;
    private int numThreads_;
    /// <summary>
    /// The number of threads in the pool.
    ///
    /// 0 means the system picks a value based on where this option proto is used
    /// (see the declaration of the specific field for more info).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int NumThreads {
      get { return numThreads_; }
      set {
        numThreads_ = value;
      }
    }

    /// <summary>Field number for the "global_name" field.</summary>
    public const int GlobalNameFieldNumber = 2;
    private string globalName_ = "";
    /// <summary>
    /// The global name of the threadpool.
    ///
    /// If empty, then the threadpool is made and used according to the scope it's
    /// in - e.g., for a session threadpool, it is used by that session only.
    ///
    /// If non-empty, then:
    /// - a global threadpool associated with this name is looked
    ///   up or created. This allows, for example, sharing one threadpool across
    ///   many sessions (e.g., like the default behavior, if
    ///   inter_op_parallelism_threads is not configured), but still partitioning
    ///   into a large and small pool.
    /// - if the threadpool for this global_name already exists, then it is an
    ///   error if the existing pool was created using a different num_threads
    ///   value as is specified on this call.
    /// - threadpools created this way are never garbage collected.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string GlobalName {
      get { return globalName_; }
      set {
        globalName_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ThreadPoolOptionProto);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ThreadPoolOptionProto other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (NumThreads != other.NumThreads) return false;
      if (GlobalName != other.GlobalName) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (NumThreads != 0) hash ^= NumThreads.GetHashCode();
      if (GlobalName.Length != 0) hash ^= GlobalName.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (NumThreads != 0) {
        output.WriteRawTag(8);
        output.WriteInt32(NumThreads);
      }
      if (GlobalName.Length != 0) {
        output.WriteRawTag(18);
        output.WriteString(GlobalName);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (NumThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumThreads);
      }
      if (GlobalName.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(GlobalName);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ThreadPoolOptionProto other) {
      if (other == null) {
        return;
      }
      if (other.NumThreads != 0) {
        NumThreads = other.NumThreads;
      }
      if (other.GlobalName.Length != 0) {
        GlobalName = other.GlobalName;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            NumThreads = input.ReadInt32();
            break;
          }
          case 18: {
            GlobalName = input.ReadString();
            break;
          }
        }
      }
    }

  }

  public sealed partial class RPCOptions : pb::IMessage<RPCOptions> {
    private static readonly pb::MessageParser<RPCOptions> _parser = new pb::MessageParser<RPCOptions>(() => new RPCOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RPCOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions(RPCOptions other) : this() {
      useRpcForInprocessMaster_ = other.useRpcForInprocessMaster_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RPCOptions Clone() {
      return new RPCOptions(this);
    }

    /// <summary>Field number for the "use_rpc_for_inprocess_master" field.</summary>
    public const int UseRpcForInprocessMasterFieldNumber = 1;
    private bool useRpcForInprocessMaster_;
    /// <summary>
    /// If true, always use RPC to contact the session target.
    ///
    /// If false (the default option), TensorFlow may use an optimized
    /// transport for client-master communication that avoids the RPC
    /// stack. This option is primarily for used testing the RPC stack.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool UseRpcForInprocessMaster {
      get { return useRpcForInprocessMaster_; }
      set {
        useRpcForInprocessMaster_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RPCOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RPCOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (UseRpcForInprocessMaster != other.UseRpcForInprocessMaster) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (UseRpcForInprocessMaster != false) hash ^= UseRpcForInprocessMaster.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (UseRpcForInprocessMaster != false) {
        output.WriteRawTag(8);
        output.WriteBool(UseRpcForInprocessMaster);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (UseRpcForInprocessMaster != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RPCOptions other) {
      if (other == null) {
        return;
      }
      if (other.UseRpcForInprocessMaster != false) {
        UseRpcForInprocessMaster = other.UseRpcForInprocessMaster;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            UseRpcForInprocessMaster = input.ReadBool();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Session configuration parameters.
  /// The system picks appropriate values for fields that are not set.
  /// </summary>
  public sealed partial class ConfigProto : pb::IMessage<ConfigProto> {
    private static readonly pb::MessageParser<ConfigProto> _parser = new pb::MessageParser<ConfigProto>(() => new ConfigProto());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<ConfigProto> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto(ConfigProto other) : this() {
      deviceCount_ = other.deviceCount_.Clone();
      intraOpParallelismThreads_ = other.intraOpParallelismThreads_;
      interOpParallelismThreads_ = other.interOpParallelismThreads_;
      usePerSessionThreads_ = other.usePerSessionThreads_;
      sessionInterOpThreadPool_ = other.sessionInterOpThreadPool_.Clone();
      placementPeriod_ = other.placementPeriod_;
      deviceFilters_ = other.deviceFilters_.Clone();
      GpuOptions = other.gpuOptions_ != null ? other.GpuOptions.Clone() : null;
      allowSoftPlacement_ = other.allowSoftPlacement_;
      logDevicePlacement_ = other.logDevicePlacement_;
      GraphOptions = other.graphOptions_ != null ? other.GraphOptions.Clone() : null;
      operationTimeoutInMs_ = other.operationTimeoutInMs_;
      RpcOptions = other.rpcOptions_ != null ? other.RpcOptions.Clone() : null;
      ClusterDef = other.clusterDef_ != null ? other.ClusterDef.Clone() : null;
      isolateSessionState_ = other.isolateSessionState_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public ConfigProto Clone() {
      return new ConfigProto(this);
    }

    /// <summary>Field number for the "device_count" field.</summary>
    public const int DeviceCountFieldNumber = 1;
    private static readonly pbc::MapField<string, int>.Codec _map_deviceCount_codec
        = new pbc::MapField<string, int>.Codec(pb::FieldCodec.ForString(10), pb::FieldCodec.ForInt32(16), 10);
    private readonly pbc::MapField<string, int> deviceCount_ = new pbc::MapField<string, int>();
    /// <summary>
    /// Map from device type name (e.g., "CPU" or "GPU" ) to maximum
    /// number of devices of that type to use.  If a particular device
    /// type is not found in the map, the system picks an appropriate
    /// number.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::MapField<string, int> DeviceCount {
      get { return deviceCount_; }
    }

    /// <summary>Field number for the "intra_op_parallelism_threads" field.</summary>
    public const int IntraOpParallelismThreadsFieldNumber = 2;
    private int intraOpParallelismThreads_;
    /// <summary>
    /// The execution of an individual op (for some op types) can be
    /// parallelized on a pool of intra_op_parallelism_threads.
    /// 0 means the system picks an appropriate number.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int IntraOpParallelismThreads {
      get { return intraOpParallelismThreads_; }
      set {
        intraOpParallelismThreads_ = value;
      }
    }

    /// <summary>Field number for the "inter_op_parallelism_threads" field.</summary>
    public const int InterOpParallelismThreadsFieldNumber = 5;
    private int interOpParallelismThreads_;
    /// <summary>
    /// Nodes that perform blocking operations are enqueued on a pool of
    /// inter_op_parallelism_threads available in each process.
    ///
    /// 0 means the system picks an appropriate number.
    ///
    /// Note that the first Session created in the process sets the
    /// number of threads for all future sessions unless use_per_session_threads is
    /// true or session_inter_op_thread_pool is configured.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int InterOpParallelismThreads {
      get { return interOpParallelismThreads_; }
      set {
        interOpParallelismThreads_ = value;
      }
    }

    /// <summary>Field number for the "use_per_session_threads" field.</summary>
    public const int UsePerSessionThreadsFieldNumber = 9;
    private bool usePerSessionThreads_;
    /// <summary>
    /// If true, use a new set of threads for this session rather than the global
    /// pool of threads. Only supported by direct sessions.
    ///
    /// If false, use the global threads created by the first session, or the
    /// per-session thread pools configured by session_inter_op_thread_pool.
    ///
    /// This option is deprecated. The same effect can be achieved by setting
    /// session_inter_op_thread_pool to have one element, whose num_threads equals
    /// inter_op_parallelism_threads.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool UsePerSessionThreads {
      get { return usePerSessionThreads_; }
      set {
        usePerSessionThreads_ = value;
      }
    }

    /// <summary>Field number for the "session_inter_op_thread_pool" field.</summary>
    public const int SessionInterOpThreadPoolFieldNumber = 12;
    private static readonly pb::FieldCodec<global::Vision.Tensorflow.Proto.ThreadPoolOptionProto> _repeated_sessionInterOpThreadPool_codec
        = pb::FieldCodec.ForMessage(98, global::Vision.Tensorflow.Proto.ThreadPoolOptionProto.Parser);
    private readonly pbc::RepeatedField<global::Vision.Tensorflow.Proto.ThreadPoolOptionProto> sessionInterOpThreadPool_ = new pbc::RepeatedField<global::Vision.Tensorflow.Proto.ThreadPoolOptionProto>();
    /// <summary>
    /// This option is experimental - it may be replaced with a different mechanism
    /// in the future.
    ///
    /// Configures session thread pools. If this is configured, then RunOptions for
    /// a Run call can select the thread pool to use.
    ///
    /// The intended use is for when some session invocations need to run in a
    /// background pool limited to a small number of threads:
    /// - For example, a session may be configured to have one large pool (for
    /// regular compute) and one small pool (for periodic, low priority work);
    /// using the small pool is currently the mechanism for limiting the inter-op
    /// parallelism of the low priority work.  Note that it does not limit the
    /// parallelism of work spawned by a single op kernel implementation.
    /// - Using this setting is normally not needed in training, but may help some
    /// serving use cases.
    /// - It is also generally recommended to set the global_name field of this
    /// proto, to avoid creating multiple large pools. It is typically better to
    /// run the non-low-priority work, even across sessions, in a single large
    /// pool.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Vision.Tensorflow.Proto.ThreadPoolOptionProto> SessionInterOpThreadPool {
      get { return sessionInterOpThreadPool_; }
    }

    /// <summary>Field number for the "placement_period" field.</summary>
    public const int PlacementPeriodFieldNumber = 3;
    private int placementPeriod_;
    /// <summary>
    /// Assignment of Nodes to Devices is recomputed every placement_period
    /// steps until the system warms up (at which point the recomputation
    /// typically slows down automatically).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int PlacementPeriod {
      get { return placementPeriod_; }
      set {
        placementPeriod_ = value;
      }
    }

    /// <summary>Field number for the "device_filters" field.</summary>
    public const int DeviceFiltersFieldNumber = 4;
    private static readonly pb::FieldCodec<string> _repeated_deviceFilters_codec
        = pb::FieldCodec.ForString(34);
    private readonly pbc::RepeatedField<string> deviceFilters_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// When any filters are present sessions will ignore all devices which do not
    /// match the filters. Each filter can be partially specified, e.g. "/job:ps"
    /// "/job:worker/replica:3", etc.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> DeviceFilters {
      get { return deviceFilters_; }
    }

    /// <summary>Field number for the "gpu_options" field.</summary>
    public const int GpuOptionsFieldNumber = 6;
    private global::Vision.Tensorflow.Proto.GPUOptions gpuOptions_;
    /// <summary>
    /// Options that apply to all GPUs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.GPUOptions GpuOptions {
      get { return gpuOptions_; }
      set {
        gpuOptions_ = value;
      }
    }

    /// <summary>Field number for the "allow_soft_placement" field.</summary>
    public const int AllowSoftPlacementFieldNumber = 7;
    private bool allowSoftPlacement_;
    /// <summary>
    /// Whether soft placement is allowed. If allow_soft_placement is true,
    /// an op will be placed on CPU if
    ///   1. there's no GPU implementation for the OP
    /// or
    ///   2. no GPU devices are known or registered
    /// or
    ///   3. need to co-locate with reftype input(s) which are from CPU.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool AllowSoftPlacement {
      get { return allowSoftPlacement_; }
      set {
        allowSoftPlacement_ = value;
      }
    }

    /// <summary>Field number for the "log_device_placement" field.</summary>
    public const int LogDevicePlacementFieldNumber = 8;
    private bool logDevicePlacement_;
    /// <summary>
    /// Whether device placements should be logged.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool LogDevicePlacement {
      get { return logDevicePlacement_; }
      set {
        logDevicePlacement_ = value;
      }
    }

    /// <summary>Field number for the "graph_options" field.</summary>
    public const int GraphOptionsFieldNumber = 10;
    private global::Vision.Tensorflow.Proto.GraphOptions graphOptions_;
    /// <summary>
    /// Options that apply to all graphs.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.GraphOptions GraphOptions {
      get { return graphOptions_; }
      set {
        graphOptions_ = value;
      }
    }

    /// <summary>Field number for the "operation_timeout_in_ms" field.</summary>
    public const int OperationTimeoutInMsFieldNumber = 11;
    private long operationTimeoutInMs_;
    /// <summary>
    /// Global timeout for all blocking operations in this session.  If non-zero,
    /// and not overridden on a per-operation basis, this value will be used as the
    /// deadline for all blocking operations.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long OperationTimeoutInMs {
      get { return operationTimeoutInMs_; }
      set {
        operationTimeoutInMs_ = value;
      }
    }

    /// <summary>Field number for the "rpc_options" field.</summary>
    public const int RpcOptionsFieldNumber = 13;
    private global::Vision.Tensorflow.Proto.RPCOptions rpcOptions_;
    /// <summary>
    /// Options that apply when this session uses the distributed runtime.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.RPCOptions RpcOptions {
      get { return rpcOptions_; }
      set {
        rpcOptions_ = value;
      }
    }

    /// <summary>Field number for the "cluster_def" field.</summary>
    public const int ClusterDefFieldNumber = 14;
    private global::Vision.Tensorflow.Proto.ClusterDef clusterDef_;
    /// <summary>
    /// Optional list of all workers to use in this session.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.ClusterDef ClusterDef {
      get { return clusterDef_; }
      set {
        clusterDef_ = value;
      }
    }

    /// <summary>Field number for the "isolate_session_state" field.</summary>
    public const int IsolateSessionStateFieldNumber = 15;
    private bool isolateSessionState_;
    /// <summary>
    /// If true, any resources such as Variables used in the session will not be
    /// shared with other sessions.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool IsolateSessionState {
      get { return isolateSessionState_; }
      set {
        isolateSessionState_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as ConfigProto);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(ConfigProto other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!DeviceCount.Equals(other.DeviceCount)) return false;
      if (IntraOpParallelismThreads != other.IntraOpParallelismThreads) return false;
      if (InterOpParallelismThreads != other.InterOpParallelismThreads) return false;
      if (UsePerSessionThreads != other.UsePerSessionThreads) return false;
      if(!sessionInterOpThreadPool_.Equals(other.sessionInterOpThreadPool_)) return false;
      if (PlacementPeriod != other.PlacementPeriod) return false;
      if(!deviceFilters_.Equals(other.deviceFilters_)) return false;
      if (!object.Equals(GpuOptions, other.GpuOptions)) return false;
      if (AllowSoftPlacement != other.AllowSoftPlacement) return false;
      if (LogDevicePlacement != other.LogDevicePlacement) return false;
      if (!object.Equals(GraphOptions, other.GraphOptions)) return false;
      if (OperationTimeoutInMs != other.OperationTimeoutInMs) return false;
      if (!object.Equals(RpcOptions, other.RpcOptions)) return false;
      if (!object.Equals(ClusterDef, other.ClusterDef)) return false;
      if (IsolateSessionState != other.IsolateSessionState) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= DeviceCount.GetHashCode();
      if (IntraOpParallelismThreads != 0) hash ^= IntraOpParallelismThreads.GetHashCode();
      if (InterOpParallelismThreads != 0) hash ^= InterOpParallelismThreads.GetHashCode();
      if (UsePerSessionThreads != false) hash ^= UsePerSessionThreads.GetHashCode();
      hash ^= sessionInterOpThreadPool_.GetHashCode();
      if (PlacementPeriod != 0) hash ^= PlacementPeriod.GetHashCode();
      hash ^= deviceFilters_.GetHashCode();
      if (gpuOptions_ != null) hash ^= GpuOptions.GetHashCode();
      if (AllowSoftPlacement != false) hash ^= AllowSoftPlacement.GetHashCode();
      if (LogDevicePlacement != false) hash ^= LogDevicePlacement.GetHashCode();
      if (graphOptions_ != null) hash ^= GraphOptions.GetHashCode();
      if (OperationTimeoutInMs != 0L) hash ^= OperationTimeoutInMs.GetHashCode();
      if (rpcOptions_ != null) hash ^= RpcOptions.GetHashCode();
      if (clusterDef_ != null) hash ^= ClusterDef.GetHashCode();
      if (IsolateSessionState != false) hash ^= IsolateSessionState.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      deviceCount_.WriteTo(output, _map_deviceCount_codec);
      if (IntraOpParallelismThreads != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(IntraOpParallelismThreads);
      }
      if (PlacementPeriod != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(PlacementPeriod);
      }
      deviceFilters_.WriteTo(output, _repeated_deviceFilters_codec);
      if (InterOpParallelismThreads != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(InterOpParallelismThreads);
      }
      if (gpuOptions_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(GpuOptions);
      }
      if (AllowSoftPlacement != false) {
        output.WriteRawTag(56);
        output.WriteBool(AllowSoftPlacement);
      }
      if (LogDevicePlacement != false) {
        output.WriteRawTag(64);
        output.WriteBool(LogDevicePlacement);
      }
      if (UsePerSessionThreads != false) {
        output.WriteRawTag(72);
        output.WriteBool(UsePerSessionThreads);
      }
      if (graphOptions_ != null) {
        output.WriteRawTag(82);
        output.WriteMessage(GraphOptions);
      }
      if (OperationTimeoutInMs != 0L) {
        output.WriteRawTag(88);
        output.WriteInt64(OperationTimeoutInMs);
      }
      sessionInterOpThreadPool_.WriteTo(output, _repeated_sessionInterOpThreadPool_codec);
      if (rpcOptions_ != null) {
        output.WriteRawTag(106);
        output.WriteMessage(RpcOptions);
      }
      if (clusterDef_ != null) {
        output.WriteRawTag(114);
        output.WriteMessage(ClusterDef);
      }
      if (IsolateSessionState != false) {
        output.WriteRawTag(120);
        output.WriteBool(IsolateSessionState);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += deviceCount_.CalculateSize(_map_deviceCount_codec);
      if (IntraOpParallelismThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(IntraOpParallelismThreads);
      }
      if (InterOpParallelismThreads != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(InterOpParallelismThreads);
      }
      if (UsePerSessionThreads != false) {
        size += 1 + 1;
      }
      size += sessionInterOpThreadPool_.CalculateSize(_repeated_sessionInterOpThreadPool_codec);
      if (PlacementPeriod != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(PlacementPeriod);
      }
      size += deviceFilters_.CalculateSize(_repeated_deviceFilters_codec);
      if (gpuOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(GpuOptions);
      }
      if (AllowSoftPlacement != false) {
        size += 1 + 1;
      }
      if (LogDevicePlacement != false) {
        size += 1 + 1;
      }
      if (graphOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(GraphOptions);
      }
      if (OperationTimeoutInMs != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(OperationTimeoutInMs);
      }
      if (rpcOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(RpcOptions);
      }
      if (clusterDef_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(ClusterDef);
      }
      if (IsolateSessionState != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(ConfigProto other) {
      if (other == null) {
        return;
      }
      deviceCount_.Add(other.deviceCount_);
      if (other.IntraOpParallelismThreads != 0) {
        IntraOpParallelismThreads = other.IntraOpParallelismThreads;
      }
      if (other.InterOpParallelismThreads != 0) {
        InterOpParallelismThreads = other.InterOpParallelismThreads;
      }
      if (other.UsePerSessionThreads != false) {
        UsePerSessionThreads = other.UsePerSessionThreads;
      }
      sessionInterOpThreadPool_.Add(other.sessionInterOpThreadPool_);
      if (other.PlacementPeriod != 0) {
        PlacementPeriod = other.PlacementPeriod;
      }
      deviceFilters_.Add(other.deviceFilters_);
      if (other.gpuOptions_ != null) {
        if (gpuOptions_ == null) {
          gpuOptions_ = new global::Vision.Tensorflow.Proto.GPUOptions();
        }
        GpuOptions.MergeFrom(other.GpuOptions);
      }
      if (other.AllowSoftPlacement != false) {
        AllowSoftPlacement = other.AllowSoftPlacement;
      }
      if (other.LogDevicePlacement != false) {
        LogDevicePlacement = other.LogDevicePlacement;
      }
      if (other.graphOptions_ != null) {
        if (graphOptions_ == null) {
          graphOptions_ = new global::Vision.Tensorflow.Proto.GraphOptions();
        }
        GraphOptions.MergeFrom(other.GraphOptions);
      }
      if (other.OperationTimeoutInMs != 0L) {
        OperationTimeoutInMs = other.OperationTimeoutInMs;
      }
      if (other.rpcOptions_ != null) {
        if (rpcOptions_ == null) {
          rpcOptions_ = new global::Vision.Tensorflow.Proto.RPCOptions();
        }
        RpcOptions.MergeFrom(other.RpcOptions);
      }
      if (other.clusterDef_ != null) {
        if (clusterDef_ == null) {
          clusterDef_ = new global::Vision.Tensorflow.Proto.ClusterDef();
        }
        ClusterDef.MergeFrom(other.ClusterDef);
      }
      if (other.IsolateSessionState != false) {
        IsolateSessionState = other.IsolateSessionState;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            deviceCount_.AddEntriesFrom(input, _map_deviceCount_codec);
            break;
          }
          case 16: {
            IntraOpParallelismThreads = input.ReadInt32();
            break;
          }
          case 24: {
            PlacementPeriod = input.ReadInt32();
            break;
          }
          case 34: {
            deviceFilters_.AddEntriesFrom(input, _repeated_deviceFilters_codec);
            break;
          }
          case 40: {
            InterOpParallelismThreads = input.ReadInt32();
            break;
          }
          case 50: {
            if (gpuOptions_ == null) {
              gpuOptions_ = new global::Vision.Tensorflow.Proto.GPUOptions();
            }
            input.ReadMessage(gpuOptions_);
            break;
          }
          case 56: {
            AllowSoftPlacement = input.ReadBool();
            break;
          }
          case 64: {
            LogDevicePlacement = input.ReadBool();
            break;
          }
          case 72: {
            UsePerSessionThreads = input.ReadBool();
            break;
          }
          case 82: {
            if (graphOptions_ == null) {
              graphOptions_ = new global::Vision.Tensorflow.Proto.GraphOptions();
            }
            input.ReadMessage(graphOptions_);
            break;
          }
          case 88: {
            OperationTimeoutInMs = input.ReadInt64();
            break;
          }
          case 98: {
            sessionInterOpThreadPool_.AddEntriesFrom(input, _repeated_sessionInterOpThreadPool_codec);
            break;
          }
          case 106: {
            if (rpcOptions_ == null) {
              rpcOptions_ = new global::Vision.Tensorflow.Proto.RPCOptions();
            }
            input.ReadMessage(rpcOptions_);
            break;
          }
          case 114: {
            if (clusterDef_ == null) {
              clusterDef_ = new global::Vision.Tensorflow.Proto.ClusterDef();
            }
            input.ReadMessage(clusterDef_);
            break;
          }
          case 120: {
            IsolateSessionState = input.ReadBool();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Options for a single Run() call.
  /// </summary>
  public sealed partial class RunOptions : pb::IMessage<RunOptions> {
    private static readonly pb::MessageParser<RunOptions> _parser = new pb::MessageParser<RunOptions>(() => new RunOptions());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RunOptions> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions(RunOptions other) : this() {
      traceLevel_ = other.traceLevel_;
      timeoutInMs_ = other.timeoutInMs_;
      interOpThreadPool_ = other.interOpThreadPool_;
      outputPartitionGraphs_ = other.outputPartitionGraphs_;
      DebugOptions = other.debugOptions_ != null ? other.DebugOptions.Clone() : null;
      reportTensorAllocationsUponOom_ = other.reportTensorAllocationsUponOom_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunOptions Clone() {
      return new RunOptions(this);
    }

    /// <summary>Field number for the "trace_level" field.</summary>
    public const int TraceLevelFieldNumber = 1;
    private global::Vision.Tensorflow.Proto.RunOptions.Types.TraceLevel traceLevel_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.RunOptions.Types.TraceLevel TraceLevel {
      get { return traceLevel_; }
      set {
        traceLevel_ = value;
      }
    }

    /// <summary>Field number for the "timeout_in_ms" field.</summary>
    public const int TimeoutInMsFieldNumber = 2;
    private long timeoutInMs_;
    /// <summary>
    /// Time to wait for operation to complete in milliseconds.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public long TimeoutInMs {
      get { return timeoutInMs_; }
      set {
        timeoutInMs_ = value;
      }
    }

    /// <summary>Field number for the "inter_op_thread_pool" field.</summary>
    public const int InterOpThreadPoolFieldNumber = 3;
    private int interOpThreadPool_;
    /// <summary>
    /// The thread pool to use, if session_inter_op_thread_pool is configured.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int InterOpThreadPool {
      get { return interOpThreadPool_; }
      set {
        interOpThreadPool_ = value;
      }
    }

    /// <summary>Field number for the "output_partition_graphs" field.</summary>
    public const int OutputPartitionGraphsFieldNumber = 5;
    private bool outputPartitionGraphs_;
    /// <summary>
    /// Whether the partition graph(s) executed by the executor(s) should be
    /// outputted via RunMetadata.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool OutputPartitionGraphs {
      get { return outputPartitionGraphs_; }
      set {
        outputPartitionGraphs_ = value;
      }
    }

    /// <summary>Field number for the "debug_options" field.</summary>
    public const int DebugOptionsFieldNumber = 6;
    private global::Vision.Tensorflow.Proto.DebugOptions debugOptions_;
    /// <summary>
    /// EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.DebugOptions DebugOptions {
      get { return debugOptions_; }
      set {
        debugOptions_ = value;
      }
    }

    /// <summary>Field number for the "report_tensor_allocations_upon_oom" field.</summary>
    public const int ReportTensorAllocationsUponOomFieldNumber = 7;
    private bool reportTensorAllocationsUponOom_;
    /// <summary>
    /// When enabled, causes tensor alllocation information to be included in
    /// the error message when the Run() call fails because the allocator ran
    /// out of memory (OOM).
    ///
    /// Enabling this option can slow down the Run() call.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ReportTensorAllocationsUponOom {
      get { return reportTensorAllocationsUponOom_; }
      set {
        reportTensorAllocationsUponOom_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RunOptions);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RunOptions other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (TraceLevel != other.TraceLevel) return false;
      if (TimeoutInMs != other.TimeoutInMs) return false;
      if (InterOpThreadPool != other.InterOpThreadPool) return false;
      if (OutputPartitionGraphs != other.OutputPartitionGraphs) return false;
      if (!object.Equals(DebugOptions, other.DebugOptions)) return false;
      if (ReportTensorAllocationsUponOom != other.ReportTensorAllocationsUponOom) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (TraceLevel != 0) hash ^= TraceLevel.GetHashCode();
      if (TimeoutInMs != 0L) hash ^= TimeoutInMs.GetHashCode();
      if (InterOpThreadPool != 0) hash ^= InterOpThreadPool.GetHashCode();
      if (OutputPartitionGraphs != false) hash ^= OutputPartitionGraphs.GetHashCode();
      if (debugOptions_ != null) hash ^= DebugOptions.GetHashCode();
      if (ReportTensorAllocationsUponOom != false) hash ^= ReportTensorAllocationsUponOom.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (TraceLevel != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) TraceLevel);
      }
      if (TimeoutInMs != 0L) {
        output.WriteRawTag(16);
        output.WriteInt64(TimeoutInMs);
      }
      if (InterOpThreadPool != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(InterOpThreadPool);
      }
      if (OutputPartitionGraphs != false) {
        output.WriteRawTag(40);
        output.WriteBool(OutputPartitionGraphs);
      }
      if (debugOptions_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(DebugOptions);
      }
      if (ReportTensorAllocationsUponOom != false) {
        output.WriteRawTag(56);
        output.WriteBool(ReportTensorAllocationsUponOom);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (TraceLevel != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) TraceLevel);
      }
      if (TimeoutInMs != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(TimeoutInMs);
      }
      if (InterOpThreadPool != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(InterOpThreadPool);
      }
      if (OutputPartitionGraphs != false) {
        size += 1 + 1;
      }
      if (debugOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(DebugOptions);
      }
      if (ReportTensorAllocationsUponOom != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RunOptions other) {
      if (other == null) {
        return;
      }
      if (other.TraceLevel != 0) {
        TraceLevel = other.TraceLevel;
      }
      if (other.TimeoutInMs != 0L) {
        TimeoutInMs = other.TimeoutInMs;
      }
      if (other.InterOpThreadPool != 0) {
        InterOpThreadPool = other.InterOpThreadPool;
      }
      if (other.OutputPartitionGraphs != false) {
        OutputPartitionGraphs = other.OutputPartitionGraphs;
      }
      if (other.debugOptions_ != null) {
        if (debugOptions_ == null) {
          debugOptions_ = new global::Vision.Tensorflow.Proto.DebugOptions();
        }
        DebugOptions.MergeFrom(other.DebugOptions);
      }
      if (other.ReportTensorAllocationsUponOom != false) {
        ReportTensorAllocationsUponOom = other.ReportTensorAllocationsUponOom;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            traceLevel_ = (global::Vision.Tensorflow.Proto.RunOptions.Types.TraceLevel) input.ReadEnum();
            break;
          }
          case 16: {
            TimeoutInMs = input.ReadInt64();
            break;
          }
          case 24: {
            InterOpThreadPool = input.ReadInt32();
            break;
          }
          case 40: {
            OutputPartitionGraphs = input.ReadBool();
            break;
          }
          case 50: {
            if (debugOptions_ == null) {
              debugOptions_ = new global::Vision.Tensorflow.Proto.DebugOptions();
            }
            input.ReadMessage(debugOptions_);
            break;
          }
          case 56: {
            ReportTensorAllocationsUponOom = input.ReadBool();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the RunOptions message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// TODO(pbar) Turn this into a TraceOptions proto which allows
      /// tracing to be controlled in a more orthogonal manner?
      /// </summary>
      public enum TraceLevel {
        [pbr::OriginalName("NO_TRACE")] NoTrace = 0,
        [pbr::OriginalName("SOFTWARE_TRACE")] SoftwareTrace = 1,
        [pbr::OriginalName("HARDWARE_TRACE")] HardwareTrace = 2,
        [pbr::OriginalName("FULL_TRACE")] FullTrace = 3,
      }

    }
    #endregion

  }

  /// <summary>
  /// Metadata output (i.e., non-Tensor) for a single Run() call.
  /// </summary>
  public sealed partial class RunMetadata : pb::IMessage<RunMetadata> {
    private static readonly pb::MessageParser<RunMetadata> _parser = new pb::MessageParser<RunMetadata>(() => new RunMetadata());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RunMetadata> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Vision.Tensorflow.Proto.ConfigReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata(RunMetadata other) : this() {
      StepStats = other.stepStats_ != null ? other.StepStats.Clone() : null;
      CostGraph = other.costGraph_ != null ? other.CostGraph.Clone() : null;
      partitionGraphs_ = other.partitionGraphs_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RunMetadata Clone() {
      return new RunMetadata(this);
    }

    /// <summary>Field number for the "step_stats" field.</summary>
    public const int StepStatsFieldNumber = 1;
    private global::Vision.Tensorflow.Proto.StepStats stepStats_;
    /// <summary>
    /// Statistics traced for this step. Populated if tracing is turned on via the
    /// "RunOptions" proto.
    /// EXPERIMENTAL: The format and set of events may change in future versions.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.StepStats StepStats {
      get { return stepStats_; }
      set {
        stepStats_ = value;
      }
    }

    /// <summary>Field number for the "cost_graph" field.</summary>
    public const int CostGraphFieldNumber = 2;
    private global::Vision.Tensorflow.Proto.CostGraphDef costGraph_;
    /// <summary>
    /// The cost graph for the computation defined by the run call.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Vision.Tensorflow.Proto.CostGraphDef CostGraph {
      get { return costGraph_; }
      set {
        costGraph_ = value;
      }
    }

    /// <summary>Field number for the "partition_graphs" field.</summary>
    public const int PartitionGraphsFieldNumber = 3;
    private static readonly pb::FieldCodec<global::Vision.Tensorflow.Proto.GraphDef> _repeated_partitionGraphs_codec
        = pb::FieldCodec.ForMessage(26, global::Vision.Tensorflow.Proto.GraphDef.Parser);
    private readonly pbc::RepeatedField<global::Vision.Tensorflow.Proto.GraphDef> partitionGraphs_ = new pbc::RepeatedField<global::Vision.Tensorflow.Proto.GraphDef>();
    /// <summary>
    /// Graphs of the partitions executed by executors.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Vision.Tensorflow.Proto.GraphDef> PartitionGraphs {
      get { return partitionGraphs_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RunMetadata);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RunMetadata other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(StepStats, other.StepStats)) return false;
      if (!object.Equals(CostGraph, other.CostGraph)) return false;
      if(!partitionGraphs_.Equals(other.partitionGraphs_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (stepStats_ != null) hash ^= StepStats.GetHashCode();
      if (costGraph_ != null) hash ^= CostGraph.GetHashCode();
      hash ^= partitionGraphs_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (stepStats_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(StepStats);
      }
      if (costGraph_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(CostGraph);
      }
      partitionGraphs_.WriteTo(output, _repeated_partitionGraphs_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (stepStats_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StepStats);
      }
      if (costGraph_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(CostGraph);
      }
      size += partitionGraphs_.CalculateSize(_repeated_partitionGraphs_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RunMetadata other) {
      if (other == null) {
        return;
      }
      if (other.stepStats_ != null) {
        if (stepStats_ == null) {
          stepStats_ = new global::Vision.Tensorflow.Proto.StepStats();
        }
        StepStats.MergeFrom(other.StepStats);
      }
      if (other.costGraph_ != null) {
        if (costGraph_ == null) {
          costGraph_ = new global::Vision.Tensorflow.Proto.CostGraphDef();
        }
        CostGraph.MergeFrom(other.CostGraph);
      }
      partitionGraphs_.Add(other.partitionGraphs_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (stepStats_ == null) {
              stepStats_ = new global::Vision.Tensorflow.Proto.StepStats();
            }
            input.ReadMessage(stepStats_);
            break;
          }
          case 18: {
            if (costGraph_ == null) {
              costGraph_ = new global::Vision.Tensorflow.Proto.CostGraphDef();
            }
            input.ReadMessage(costGraph_);
            break;
          }
          case 26: {
            partitionGraphs_.AddEntriesFrom(input, _repeated_partitionGraphs_codec);
            break;
          }
        }
      }
    }

  }

  #endregion

}

#endregion Designer generated code
